{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6572436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\rujha\\OneDrive\\Desktop\\skyhack\\test_Ritvik Kumar_Rujhan N Sharma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089d6017",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     11\u001b[39m feature_columns = [\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtotal_seats\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mscheduled_ground_time_minutes\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPEOPLE_OPTED_FOR_ELECTRIC_WHEELCHAIR\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     28\u001b[39m ]\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Creating and Clean X and y\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# We fill any missing values with 0. \u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# This is a simple way to handle NaNs for tree models.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m X = \u001b[43mdf\u001b[49m[feature_columns].fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     34\u001b[39m y = df[target_column].fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Creating the Train/Test Split\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Defining Target (y) and Features (X)\n",
    "target_column = 'departure_delay_minutes'\n",
    "\n",
    "# These are all numerical features that should be known before departure\n",
    "feature_columns = [\n",
    "    'total_seats', \n",
    "    'scheduled_ground_time_minutes', \n",
    "    'minimum_turn_minutes',\n",
    "    'TOTAL_BAGS', \n",
    "    'TRANSFER_BAGGAGE', \n",
    "    'ORIGIN_BAGGAGE',\n",
    "    'TOTAL_PASSENGERS', \n",
    "    'TOTAL_LAP_CHILD', \n",
    "    'TOTAL_BASIC_ECONOMY',\n",
    "    'TOTAL_STROLLER_USERS', \n",
    "    'AVG_ADVANCE_BOOKING', \n",
    "    'LAST_MOMENT_BOOKINGS',\n",
    "    'PEOPLE_OPTED_FOR_AIRPORT_WHEELCHAIR',\n",
    "    'PEOPLE_OPTED_FOR_UNACCOMPANIED_MINOR',\n",
    "    'PEOPLE_OPTED_FOR_MANUAL_WHEELCHAIR',\n",
    "    'PEOPLE_OPTED_FOR_ELECTRIC_WHEELCHAIR'\n",
    "]\n",
    "\n",
    "# Creating and Clean X and y\n",
    "# We fill any missing values with 0. \n",
    "# This is a simple way to handle NaNs for tree models.\n",
    "X = df[feature_columns].fillna(0)\n",
    "y = df[target_column].fillna(0)\n",
    "\n",
    "# Creating the Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Training Random Forest \n",
    "print(\"--- Random Forest ---\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred_rf))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "\n",
    "\n",
    "# Training XGBoost \n",
    "print(\"\\n--- XGBoost ---\")\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred_xgb))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest (with Feature Engineering) ---\n",
      "R2 score: 0.40188657325942057\n",
      "MSE: 2747.2344987037036\n",
      "\n",
      "--- XGBoost (with Feature Engineering) ---\n",
      "R2 score: 0.3677566647529602\n",
      "MSE: 2903.9990234375\n"
     ]
    }
   ],
   "source": [
    "# Defining Target (y)\n",
    "target_column = 'departure_delay_minutes'\n",
    "# Fill NaNs in the target (e.g., with 0 or mean)\n",
    "y = df[target_column].fillna(0)\n",
    "\n",
    "# Extracting new time-based features\n",
    "df['scheduled_departure_datetime_local']=pd.to_datetime(df['scheduled_departure_datetime_local'], dayfirst=True)\n",
    "df['departure_hour'] = df['scheduled_departure_datetime_local'].dt.hour\n",
    "df['departure_day_of_week'] = df['scheduled_departure_datetime_local'].dt.dayofweek # 0=Monday, 6=Sunday\n",
    "df['departure_month'] = df['scheduled_departure_datetime_local'].dt.month\n",
    "\n",
    "# One-Hot Encoding Categorical Features\n",
    "# This will create new columns \n",
    "# We'll just do the departure station for now\n",
    "categorical_cols = ['scheduled_departure_station_code']\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True, dummy_na=True)\n",
    "\n",
    "# Define the NEW Feature List (X) ---\n",
    "# Start with our original numerical features\n",
    "feature_columns = [\n",
    "    'total_seats', \n",
    "    'scheduled_ground_time_minutes', \n",
    "    'minimum_turn_minutes',\n",
    "    'TOTAL_BAGS', \n",
    "    'TRANSFER_BAGGAGE', \n",
    "    'ORIGIN_BAGGAGE',\n",
    "    'TOTAL_PASSENGERS', \n",
    "    'TOTAL_LAP_CHILD', \n",
    "    'TOTAL_BASIC_ECONOMY',\n",
    "    'TOTAL_STROLLER_USERS', \n",
    "    'AVG_ADVANCE_BOOKING', \n",
    "    'LAST_MOMENT_BOOKINGS',\n",
    "    'PEOPLE_OPTED_FOR_AIRPORT_WHEELCHAIR',\n",
    "    'PEOPLE_OPTED_FOR_UNACCOMPANIED_MINOR',\n",
    "    'PEOPLE_OPTED_FOR_MANUAL_WHEELCHAIR',\n",
    "    'PEOPLE_OPTED_FOR_ELECTRIC_WHEELCHAIR'\n",
    "]\n",
    "\n",
    "# Add our new engineered features\n",
    "new_time_features = ['departure_hour', 'departure_day_of_week', 'departure_month']\n",
    "# Get the list of new encoded station columns\n",
    "encoded_station_columns = [col for col in df_encoded.columns if 'scheduled_departure_station_code_' in col]\n",
    "\n",
    "# Combine all features into one big list\n",
    "all_features = feature_columns + new_time_features + encoded_station_columns\n",
    "\n",
    "# Create the final X matrix from the encoded DataFrame\n",
    "X = df_encoded[all_features].fillna(0)\n",
    "\n",
    "# Create the Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Random Forest ---\n",
    "print(\"--- Random Forest (with Feature Engineering) ---\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1 speeds it up\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred_rf))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "\n",
    "# Train XGBoost  ---\n",
    "print(\"\\n--- XGBoost (with Feature Engineering) ---\")\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred_xgb))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a58aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- KNN (with Feature Engineering) ---\n",
      "R2 score: 0.24655691182145045\n",
      "MSE: 3460.6894814814814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "print(\"\\n--- KNN (with Feature Engineering) ---\")\n",
    "\n",
    "# Creating the model\n",
    "knn_model=KNeighborsRegressor(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "# Training the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_knn= knn_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred_knn))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a52339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Linear Regression (with Feature Engineering) ---\n",
      "R2 score: 0.05470331635292969\n",
      "MSE: 4341.904971064648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Training Linear Regression (with Feature Engineering) for comparison\n",
    "# To prove that our data is complex and non-linear\n",
    "print(\"\\n--- Linear Regression (with Feature Engineering) ---\")\n",
    "\n",
    "# 1. Create the model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# 2. Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate the results\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred_lr))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_lr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46142705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Cross-Validation ---\n",
      "R2 Scores for each of the 5 folds: [-0.14550944 -1.29976153  0.35224027  0.1984921  -0.12780573]\n",
      "Average R2 Score (Mean): -0.20446886433350536\n",
      "Std Deviation of R2 Scores: 0.5798831061754305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# --- Cross-Validation ---\n",
    "\n",
    "# (We use the same settings as before)\n",
    "rf_model_cv = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 2. Running the 5-fold cross-validation\n",
    "\n",
    "# cv=5 means 5 folds\n",
    "# scoring=r2 specifies we want the R2 score\n",
    "scores = cross_val_score(rf_model_cv, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# 3. Print the results\n",
    "print(\"\\n--- Random Forest Cross-Validation ---\")\n",
    "print(\"R2 Scores for each of the 5 folds:\", scores)\n",
    "print(\"Average R2 Score (Mean):\", scores.mean())\n",
    "print(\"Std Deviation of R2 Scores:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c0bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CV (Stable Model - No One-Hot Encoding) ---\n",
      "R2 Scores (5 folds): [-0.15021178 -1.29466913  0.35445954  0.19454833 -0.12583343]\n",
      "Average R2 Score (Mean): -0.20434129261256279\n",
      "Std Deviation of R2 Scores: 0.577802660762618\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create the \"Stable\" X matrix (WITHOUT encoded columns) ---\n",
    "# (Assuming 'df_encoded', 'feature_columns', and 'new_time_features' are \n",
    "#  defined in cells above)\n",
    "\n",
    "all_features_stable = feature_columns + new_time_features\n",
    "X_stable = df_encoded[all_features_stable].fillna(0)\n",
    "# 'y' is the same target as before\n",
    "\n",
    "# --- 2. Run Cross-Validation on the \"Stable\" model ---\n",
    "print(\"\\n--- CV (Stable Model - No One-Hot Encoding) ---\")\n",
    "rf_model_cv_stable = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Run CV on the X_stable data\n",
    "scores_stable = cross_val_score(rf_model_cv_stable, X_stable, y, cv=5, scoring='r2')\n",
    "\n",
    "# 3. Print the results\n",
    "print(\"R2 Scores (5 folds):\", scores_stable)\n",
    "print(\"Average R2 Score (Mean):\", np.mean(scores_stable))\n",
    "print(\"Std Deviation of R2 Scores:\", np.std(scores_stable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44028b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Finding Feature Importances ---\n",
      "\n",
      "--- Ranked Feature Importances ---\n",
      "scheduled_ground_time_minutes           0.329414\n",
      "TOTAL_PASSENGERS                        0.100748\n",
      "departure_hour                          0.069387\n",
      "TRANSFER_BAGGAGE                        0.062462\n",
      "AVG_ADVANCE_BOOKING                     0.061881\n",
      "departure_day_of_week                   0.057807\n",
      "TOTAL_BAGS                              0.054386\n",
      "LAST_MOMENT_BOOKINGS                    0.052823\n",
      "ORIGIN_BAGGAGE                          0.047784\n",
      "TOTAL_BASIC_ECONOMY                     0.037900\n",
      "PEOPLE_OPTED_FOR_AIRPORT_WHEELCHAIR     0.027590\n",
      "minimum_turn_minutes                    0.027197\n",
      "TOTAL_STROLLER_USERS                    0.022405\n",
      "total_seats                             0.019193\n",
      "TOTAL_LAP_CHILD                         0.011662\n",
      "PEOPLE_OPTED_FOR_MANUAL_WHEELCHAIR      0.008632\n",
      "PEOPLE_OPTED_FOR_UNACCOMPANIED_MINOR    0.006766\n",
      "PEOPLE_OPTED_FOR_ELECTRIC_WHEELCHAIR    0.001963\n",
      "departure_month                         0.000000\n",
      "dtype: float64\n",
      "\n",
      "--- 2. Created 'X_top_features' with: ['scheduled_ground_time_minutes', 'TOTAL_PASSENGERS', 'departure_hour', 'TRANSFER_BAGGAGE', 'AVG_ADVANCE_BOOKING', 'departure_day_of_week', 'TOTAL_BAGS', 'LAST_MOMENT_BOOKINGS', 'ORIGIN_BAGGAGE', 'TOTAL_BASIC_ECONOMY'] ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# X_stable = df_encoded[all_features_stable].fillna(0)\n",
    "# y = df[target_column].fillna(0)\n",
    "\n",
    "print(\"--- 1. Finding Feature Importances ---\")\n",
    "\n",
    "# Training a Model on ALL Stable Features ---\n",
    "# We fit on the full X_stable and y to get the best importance ranking\n",
    "rf_feature_finder = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_feature_finder.fit(X_stable, y)\n",
    "\n",
    "# Displaying the Feature Importances \n",
    "print(\"\\n--- Ranked Feature Importances ---\")\n",
    "\n",
    "# Creating a pandas Series to view the features and their scores\n",
    "importances = pd.Series(\n",
    "    rf_feature_finder.feature_importances_, \n",
    "    index=X_stable.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# Printing the ranked list\n",
    "print(importances)\n",
    "\n",
    "# --- Creating the New 'X_top_features' DataFrame ---\n",
    "# Selecting the top 10 features from the list\n",
    "top_10_features = importances.head(10).index.tolist()\n",
    "X_top_features = X_stable[top_10_features]\n",
    "\n",
    "print(f\"\\n--- 2. Created 'X_top_features' with: {top_10_features} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29eb8fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Random Forest on TOP 10 Features ---\n",
      "Features: ['scheduled_ground_time_minutes', 'TOTAL_PASSENGERS', 'departure_hour', 'TRANSFER_BAGGAGE', 'AVG_ADVANCE_BOOKING', 'departure_day_of_week', 'TOTAL_BAGS', 'LAST_MOMENT_BOOKINGS', 'ORIGIN_BAGGAGE', 'TOTAL_BASIC_ECONOMY']\n",
      "--------------------------------------------------\n",
      "R2 score: 0.3901\n",
      "MSE: 2801.2966\n"
     ]
    }
   ],
   "source": [
    "# ++++++++ Training the model with the new set of important features only +++++++++++\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "print(f\"--- Training Random Forest on TOP 10 Features ---\")\n",
    "print(f\"Features: {top_10_features}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Creating a new Train/Test Split ---\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_top_features, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- 3. Train Random Forest (Top 10 Features) ---\n",
    "rf_model_s = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model_s.fit(X_train_s, y_train_s)\n",
    "y_pred_rf_s = rf_model_s.predict(X_test_s)\n",
    "\n",
    "# --- 4. Evaluate the Results ---\n",
    "print(f\"R2 score: {r2_score(y_test_s, y_pred_rf_s):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test_s, y_pred_rf_s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bafebc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (Checking for Stability) CV on Top 10 Features ---\n",
      "R2 Scores (5 folds): [-0.15955042 -1.36531639  0.31027904  0.19155475 -0.16320183]\n",
      "Average R2 Score (Mean): -0.23724697003577674\n",
      "Std Deviation of R2 Scores: 0.5945949386356321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- (Checking for Stability) CV on Top 10 Features ---\")\n",
    "\n",
    "# Creating a fresh model instance\n",
    "rf_model_cv_simple = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Run CV on the new 'X_top_features'\n",
    "scores_simple = cross_val_score(rf_model_cv_simple, X_top_features, y, cv=5, scoring='r2')\n",
    "\n",
    "# 3. Print the results\n",
    "print(\"R2 Scores (5 folds):\", scores_simple)\n",
    "print(\"Average R2 Score (Mean):\", np.mean(scores_simple))\n",
    "print(\"Std Deviation of R2 Scores:\", np.std(scores_simple))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
